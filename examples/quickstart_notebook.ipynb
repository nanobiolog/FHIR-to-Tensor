{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ¥ NeuroFHIR Real-Data Quickstart\n",
                "\n",
                "Welcome to **NeuroFHIR**, the library for Geometric Deep Learning on clinical data. \n",
                "\n",
                "This notebook demonstrates how to:\n",
                "1.  **Load Patient Data**: Process local FHIR JSON files.\n",
                "2.  **Build Temporal Graphs**: Convert full patient history into graph snapshots.\n",
                "3.  **Visualizes the Graph**: Plot the connectivity of healthcare events.\n",
                "4.  **Hyperbolic Embeddings**: Embed concepts in hyperbolic space.\n",
                "5.  **Causal Discovery**: Mine potential causal edges.\n",
                "\n",
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install neurofhir polars torch networkx matplotlib\n",
                "\n",
                "import os\n",
                "import sys\n",
                "import json\n",
                "import glob\n",
                "import networkx as nx\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Ensure we can import local modules if finding from repo root\n",
                "try:\n",
                "    import neurofhir\n",
                "except ImportError:\n",
                "    # If running from repo, add parent dir\n",
                "    sys.path.append(os.path.abspath('..'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load a Patient File\n",
                "We assume you have FHIR data in the `../data` folder. If not, use the `download_sample_data.py` script provided in the repo, or upload your own bundles."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_dir = os.path.join(\"..\", \"data\", \"fhir\")\n",
                "# Look for downloaded data or just in ../data depending on extraction\n",
                "if not os.path.exists(data_dir):\n",
                "    data_dir = os.path.join(\"..\", \"data\")\n",
                "\n",
                "files = glob.glob(os.path.join(data_dir, \"*.json\"))\n",
                "\n",
                "if not files:\n",
                "    print(\"No files found! Please upload FHIR bundles to the 'data' directory.\")\n",
                "else:\n",
                "    patient_file = files[0]\n",
                "    print(f\"Selected patient file: {patient_file}\")\n",
                "    \n",
                "    with open(patient_file, 'r', encoding='utf-8') as f:\n",
                "        bundle = json.load(f)\n",
                "        resources = [e['resource'] for e in bundle.get('entry', []) if 'resource' in e]\n",
                "        print(f\"Loaded {len(resources)} FHIR resources.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Generate Temporal Graph\n",
                "We use `FHIRTemporalGraphBuilder` to slice this history into daily snapshots."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from neurofhir.temporal_builder import FHIRTemporalGraphBuilder\n",
                "\n",
                "# 1 day windows\n",
                "builder = FHIRTemporalGraphBuilder(time_window=\"1d\")\n",
                "\n",
                "snapshots = list(builder.build_snapshots(resources))\n",
                "\n",
                "print(f\"\\nGenerated {len(snapshots)} snapshots from patient history.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Visualizes the Graph\n",
                "We will pick the busiest day (snapshot with the most interactions) and plot it using NetworkX."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find snapshot with max edges\n",
                "if snapshots:\n",
                "    # Helper to count edges in dict or PyG object\n",
                "    def count_edges(snap):\n",
                "        if isinstance(snap, dict):\n",
                "            # Use 'edge_index_dict' key for raw builder output\n",
                "            if 'edge_index_dict' in snap:\n",
                "                return sum(len(v[0]) for v in snap['edge_index_dict'].values())\n",
                "            # Fallback for 'edges' key if serialized\n",
                "            if 'edges' in snap:\n",
                "                return sum(len(v[0]) for v in snap['edges'].values())\n",
                "            return 0\n",
                "        return snap.num_edges\n",
                "\n",
                "    max_snap = max(snapshots, key=count_edges)\n",
                "    idx = snapshots.index(max_snap)\n",
                "    \n",
                "    print(f\"Visualizing Snapshot {idx} (Timestamp: {max_snap.get('timestamp', 'Unknown')})\")\n",
                "    \n",
                "    # Setup NetworkX Graph\n",
                "    G = nx.DiGraph()\n",
                "    \n",
                "    edge_dict = {}\n",
                "    if isinstance(max_snap, dict):\n",
                "        edge_dict = max_snap.get('edge_index_dict', max_snap.get('edges', {}))\n",
                "    else:\n",
                "        # PyG HeteroData\n",
                "        edge_dict = max_snap.edge_index_dict\n",
                "    \n",
                "    node_colors = []\n",
                "    colors_map = {\n",
                "        \"Patient\": \"#1f77b4\",\n",
                "        \"Practitioner\": \"#2ca02c\",\n",
                "        \"Organization\": \"#d62728\",\n",
                "        \"Encounter\": \"#ff7f0e\",\n",
                "        \"Condition\": \"#9467bd\",\n",
                "        \"Observation\": \"#17becf\",\n",
                "    }\n",
                "\n",
                "    for (src_type, rel, dst_type), (src_idxs, dst_idxs) in edge_dict.items():\n",
                "        for s, d in zip(src_idxs, dst_idxs):\n",
                "            u = f\"{src_type}_{s}\"\n",
                "            v = f\"{dst_type}_{d}\"\n",
                "            G.add_node(u, color=colors_map.get(src_type, \"grey\"))\n",
                "            G.add_node(v, color=colors_map.get(dst_type, \"grey\"))\n",
                "            G.add_edge(u, v)\n",
                "            \n",
                "    # Draw\n",
                "    plt.figure(figsize=(10, 8))\n",
                "    pos = nx.spring_layout(G, k=0.6, seed=42)\n",
                "    \n",
                "    colors = [G.nodes[n].get('color', 'grey') for n in G.nodes()]\n",
                "    nx.draw(G, pos, node_color=colors, with_labels=False, node_size=300, alpha=0.9)\n",
                "    \n",
                "    # Legend\n",
                "    from matplotlib.lines import Line2D\n",
                "    legend_elements = [Line2D([0], [0], marker='o', color='w', label=k, markerfacecolor=v, markersize=10) \n",
                "                       for k, v in colors_map.items() if any(k in n for n in G.nodes())]\n",
                "    plt.legend(handles=legend_elements, loc='upper right')\n",
                "    plt.title(f\"Interactions on {str(max_snap.get('timestamp', ''))[:10]}\")\n",
                "    plt.show()\n",
                "            \n",
                "else:\n",
                "    print(\"No snapshots generated.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Hyperbolic Embeddings\n",
                "Learn hierarchical representations of medical concepts using PoincarÃ© embeddings. This places general concepts near the origin and specific concepts near the boundary of the hyperbolic ball."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from neurofhir.hyperbolic_encoder import PoincareEmbedding\n",
                "import torch\n",
                "\n",
                "# 1. Define a dummy ontology (e.g., SNOMED subset)\n",
                "ontology_map = {\n",
                "    \"Disorder\": [\"Respiratory\", \"Cardiovascular\"],\n",
                "    \"Respiratory\": [\"Asthma\", \"Pneumonia\"],\n",
                "    \"Cardiovascular\": [\"Hypertension\", \"Arrhythmia\"]\n",
                "}\n",
                "\n",
                "# Map codes to indices\n",
                "codes = [\"Disorder\", \"Respiratory\", \"Cardiovascular\", \"Asthma\", \"Pneumonia\", \"Hypertension\", \"Arrhythmia\"]\n",
                "idx_to_code = {i: code for i, code in enumerate(codes)}\n",
                "\n",
                "# 2. Initialize Model\n",
                "model = PoincareEmbedding(\n",
                "    num_embeddings=len(idx_to_code),\n",
                "    embedding_dim=2, # Use 2D for easy visualization\n",
                "    ontology_map=ontology_map,\n",
                "    idx_to_code=idx_to_code\n",
                ")\n",
                "\n",
                "# 3. Compute Embeddings (Untrained random initialization for demo)\n",
                "# In a real loop, you would optimize the loss to minimize distance between parents/children.\n",
                "ids = torch.arange(len(idx_to_code))\n",
                "vectors = model(ids).detach()\n",
                "\n",
                "# 4. Visualize in PoincarÃ© Disk\n",
                "plt.figure(figsize=(6, 6))\n",
                "plt.xlim(-1.1, 1.1)\n",
                "plt.ylim(-1.1, 1.1)\n",
                "# Draw unit circle\n",
                "circle = plt.Circle((0, 0), 1, color='black', fill=False)\n",
                "plt.gca().add_artist(circle)\n",
                "\n",
                "for i, vec in enumerate(vectors):\n",
                "    plt.scatter(vec[0], vec[1], label=idx_to_code[i])\n",
                "    plt.text(vec[0]+0.02, vec[1]+0.02, idx_to_code[i])\n",
                "\n",
                "plt.title(\"Concepts in Hyperbolic Space (Random Init)\")\n",
                "plt.grid(True, linestyle='--')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Causal Edge Mining\n",
                "Discover potential causal links (e.g., Medication -> Condition Change) from the patient history."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from neurofhir.causal_edge_miner import CausalEdgeMiner\n",
                "\n",
                "miner = CausalEdgeMiner()\n",
                "\n",
                "# Mine relationships from the loaded patient resources\n",
                "cleaned_edges = miner.mine_relationships(resources)\n",
                "\n",
                "if cleaned_edges is not None and not cleaned_edges.is_empty():\n",
                "    print(\"Found potential causal edges:\")\n",
                "    # Show top edges sorted by weight (confidence)\n",
                "    print(cleaned_edges.select([\"source\", \"relation\", \"target\", \"weight\"]).head(5))\n",
                "else:\n",
                "    print(\"No strong causal patterns found in this patient data.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}